{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mutagen\n",
    "import os\n",
    "import random\n",
    "import wave\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "import classifier\n",
    "import multi_classifier as mclass\n",
    "import irmasTestUtils as testUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = utils.load_pickled_dataset(\"preprocessed_train.pkl\")\n",
    "df_test = utils.load_pickled_dataset(\"preprocessed_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, ys = mclass.process_dataframe(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = mclass.make_model()\n",
    "#mclass.train_model(model, x, ys, batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "420/420 [==============================] - 22s 50ms/step - loss: 6.3694\n",
      "Epoch 2/30\n",
      "420/420 [==============================] - 24s 57ms/step - loss: 1.6948\n",
      "Epoch 3/30\n",
      "420/420 [==============================] - 26s 62ms/step - loss: 1.4144 0s -\n",
      "Epoch 4/30\n",
      "420/420 [==============================] - 26s 62ms/step - loss: 1.0495\n",
      "Epoch 5/30\n",
      "420/420 [==============================] - 26s 62ms/step - loss: 0.7051\n",
      "Epoch 6/30\n",
      "420/420 [==============================] - 28s 67ms/step - loss: 0.4278\n",
      "Epoch 7/30\n",
      "420/420 [==============================] - 29s 68ms/step - loss: 0.2502\n",
      "Epoch 8/30\n",
      "420/420 [==============================] - 27s 64ms/step - loss: 0.1446\n",
      "Epoch 9/30\n",
      "420/420 [==============================] - 31s 74ms/step - loss: 0.0963\n",
      "Epoch 10/30\n",
      "420/420 [==============================] - 30s 71ms/step - loss: 0.1405\n",
      "Epoch 11/30\n",
      "420/420 [==============================] - 26s 62ms/step - loss: 0.0668\n",
      "Epoch 12/30\n",
      "420/420 [==============================] - 26s 63ms/step - loss: 0.2135 1s -  - ETA: 0s - loss\n",
      "Epoch 13/30\n",
      "420/420 [==============================] - 26s 61ms/step - loss: 0.0598\n",
      "Epoch 14/30\n",
      "420/420 [==============================] - 27s 65ms/step - loss: 0.1240\n",
      "Epoch 15/30\n",
      "420/420 [==============================] - 25s 60ms/step - loss: 0.0975\n",
      "Epoch 16/30\n",
      "420/420 [==============================] - 25s 60ms/step - loss: 0.0599\n",
      "Epoch 17/30\n",
      "420/420 [==============================] - 25s 59ms/step - loss: 0.0671\n",
      "Epoch 18/30\n",
      "420/420 [==============================] - 25s 59ms/step - loss: 0.0843 2\n",
      "Epoch 19/30\n",
      "420/420 [==============================] - 25s 59ms/step - loss: 0.1105\n",
      "Epoch 20/30\n",
      "420/420 [==============================] - 25s 59ms/step - loss: 0.0509\n",
      "Epoch 21/30\n",
      "420/420 [==============================] - 26s 61ms/step - loss: 0.0365\n",
      "Epoch 22/30\n",
      "420/420 [==============================] - 25s 60ms/step - loss: 0.0565 0s - \n",
      "Epoch 23/30\n",
      "420/420 [==============================] - 25s 59ms/step - loss: 0.0777\n",
      "Epoch 24/30\n",
      "420/420 [==============================] - 25s 59ms/step - loss: 0.1009 3s - l - ET - ETA: 0s - loss: \n",
      "Epoch 25/30\n",
      "420/420 [==============================] - 25s 59ms/step - loss: 0.0484\n",
      "Epoch 26/30\n",
      "420/420 [==============================] - 25s 60ms/step - loss: 0.0588\n",
      "Epoch 27/30\n",
      "420/420 [==============================] - 25s 59ms/step - loss: 0.0891\n",
      "Epoch 28/30\n",
      "420/420 [==============================] - 24s 58ms/step - loss: 0.0413\n",
      "Epoch 29/30\n",
      "420/420 [==============================] - 24s 58ms/step - loss: 0.0349\n",
      "Epoch 30/30\n",
      "336/420 [=======================>......] - ETA: 4s - loss: 0.0198"
     ]
    }
   ],
   "source": [
    "model = classifier.make_model()\n",
    "\n",
    "classifier.train_model(model, df_train, batch_size=32, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier.get_accuracy(model, df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(model.weights)\n",
    "model.save_weights(\"classifier_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = classifier.make_model()\n",
    "test.load_weights(\"classifier_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "smaller = mclass.make_model()\n",
    "for layer in test.layers:\n",
    "    for i in range(len(smaller)):\n",
    "        for v in range(len(smaller[i].layers)):\n",
    "            if smaller[i].layers[v].name == layer.name:\n",
    "                smaller[i].layers[v].set_weights(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smaller[0].layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, ys = mclass.process_dataframe(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclass.train_model(smaller, x, ys, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=8, kernel_size=4, strides=(2,2), padding='same', input_shape=(128,259,1), name=\"conv_1\"))\n",
    "model.add(tf.keras.layers.BatchNormalization(axis=1, name=\"bn_1\"))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), name=\"mpool_1\"))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=(1,1), padding='valid', name=\"conv_2\"))\n",
    "model.add(tf.keras.layers.BatchNormalization(axis=1, name=\"bn_2\"))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), name=\"mpool_2\"))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, strides=(1,1), padding='valid', name=\"conv_3\"))\n",
    "model.add(tf.keras.layers.BatchNormalization(axis=1, name=\"bn_3\"))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), name=\"mpool_3\"))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(500, activation='relu', name=\"fc_4\"))\n",
    "model.add(tf.keras.layers.Dense(11, activation=None, name=\"fc_5\"))\n",
    "model.add(tf.keras.layers.Softmax())\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy())\n",
    "\n",
    "train_set = df.tail(-1000)\n",
    "test_set = df.head(1000)\n",
    "\n",
    "x, y = np.stack(train_set.data), np.stack(train_set.label)\n",
    "x = x.reshape((-1,128,259,1))\n",
    "print(x.shape)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "model.fit(x, y, batch_size=32, epochs=30)\n",
    "\n",
    "'''x, y = np.stack(sample['data']), np.stack(sample['label'])\n",
    "print(x.shape, y.shape)\n",
    "print(type(x), type(y))\n",
    "x, y = tf.convert_to_tensor(x, dtype=tf.float32), tf.convert_to_tensor(y, dtype=tf.float32)\n",
    "model.predict(x)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.stack(train_set.data), np.stack(train_set.label)\n",
    "x = x.reshape((-1,128,259,1))\n",
    "\n",
    "preds = np.argmax(model.predict(x), axis=1).reshape(x.shape[0], 1)\n",
    "true = np.argmax(y, axis=1)\n",
    "\n",
    "print(\"Train accuracy:\", np.sum((preds == true)*np.ones(preds.shape))/x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = np.stack(test_set.data), np.stack(test_set.label)\n",
    "x = x.reshape((-1,128,259,1))\n",
    "\n",
    "preds = np.argmax(model.predict(x), axis=1).reshape(x.shape[0], 1)\n",
    "true = np.argmax(y, axis=1)\n",
    "\n",
    "print(\"Test accuracy:\", np.sum((preds == true)*np.ones(preds.shape))/x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15 epochs - train 88.0 test 51.5\n",
    "\n",
    "\n",
    "#30 epochs - train accuracy 96.7%, test accuracy 36.8%\n",
    "#20 epochs - train accuracy 98.8%, test accuracy 47.8%\n",
    "#15 epochs - train accuracy 97.5%, test accuracy 36.4%\n",
    "#10 epochs - train accuracy 95.7%, test accuracy 44.4%\n",
    "\n",
    "arr = np.array([[5, 2], [3, 4], [6, 8]])\n",
    "print (arr)\n",
    "print (np.linalg.norm(arr))\n",
    "print (arr / np.linalg.norm(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.combine_dataset(df, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
